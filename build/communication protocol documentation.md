# communication protocol documentation 

Torcs is written in C++ while the model is written in Python 3. It is not inherently possible to send an object or variable from one to the other. In order to access the variables from one framework to the other some sort of communication protocol needs to be created. This was originally implemented via a server and, however when this was installed on any other machine than the two used for testing, the server-client communication would not work as expected. Testing this on multiple systems with the same install method, different information was received from the server and on updating to the latest version of Ubuntu the protocol broke on also on the machine it had originally been developed on. This meant that we had to re-implement a communication protocol.

The first idea was to simply re-design the server and client, however, @Kallah was interested in using something that would be less time complex than the server client interface that we had been using so far. As this project uses online reinforcement learning it is of paramount importance that everything happens as fast as possible. This is important as the model can only see where it is driving each time it receives an image. If compared to a video game, playing with 5 frames per second is much harder than playing on 60 frames per second.

The next idea was to write the images to a file on the storage medium of the machine to send the information between the model and the simulation. This can, however be potentially harmful to the hardware on the machine as SSDs have a limited number of write cycles and continuous writing to a hard drive will drastically lower the performance of that hard drive.

The last idea, which is what is currently implemented, was to use named pipes (fifo) to allow a part of the ram to be accessed as a file stream in the Operating System (OS) filesystem. This drastically increased the performance, however, there were some issues with this method. First of all, OpenCV, the image handler for this project cannot read an image directly from a stream as it wants a finite file which meant the reading of the file had to be manual. Doing this in pure python and formatting the image as a pnm file took for an image of 7204803 pixels a whole second. This meant a more efficient method of reading the information had to be implemented.

In order to understand this, one must first understand to some degree how images work in programming, and this section is going to briefly explain images in computers. An image as we know it has a finite size and is made up by pixels. An image of 20 by 20 pixels can be stored in a 2-dimentional (2D) array. Such an image, however, would only allow for the display of greyscale or black and white images. A black and white image is an image where each pixel is either 0 or 255. A grayscale image, however, is an image where any pixel is any number between and including 0 and 255, where lower numbers means closer to black and higher means closer to white. The reason why its between 0 and 255 is because each pixel is one byte or 8 bits long and 8 bits can represent 2^8 = 256 different values. For colored images, we often use the RGB model, though others exist (most commonly BGR or HSV), where there is 1 byte (8 bit) allocated to each R, G and B (Red, Green, Blue) channel. Each value can be between 0 and 255. A tool for visualizing this is using https://www.rapidtables.com/web/color/RGB_Color.html. In order then to store an RGB image, it is not enough to store just 200x200 pixels, but instead you must store 200x200x3 pixels.

Now, in Torcs, which is written in C++, we need to extract the image that is displayed to the user in Torcs and actually storing it in a variable. In order to do this, the image is extracted from the video buffer. However, the video buffer does not store an array of integers between 0 and 255, however it stores a string of letters. This is due to the way that different datatypes in programming works. The integer in C++ is 2 bytes long (16 bits) and thus storing numbers that can be stored in one byte is twice as memory heavy. To avoid this, it is not uncommon for pixels or R, G and B values to be stored as Chars. Chars in C++ are stored in 1 byte and uses the ASCII table to convert bit information to characters. This means that it is more memory efficient to store the image as a string of characters rather than as a string of integers.

But before transferring the image, the image must be resized from 640x480x3, which is the original size of the image to 320x240x3 which is a more comfortable size to feed the model. After this, the next step is to open a named pipe using a filetype called fifo and writing the image to the fifo file as characters. However, doing so would halt Torcs from moving until the image was read due to this being a stream and not an actual file. To avoid this and allow for a continuous driving, a check needed to be performed. This is done with the python model writing a 1 or 2 to a file whenever it is ready to receive a file. The 1 will be interoperated by Torcs to mean the image should be extracted as grayscale and 2 means RGB. When the model then is ready to receive the image, the model can then send that image to the model as a string of characters. However, before it sends the image, it is important that some extra information is encoded together with this other information.

In order for this to be extracted, it is important that the receiver knows the height, width and colorspace of the image (colorspace would be 3 for RGB as it has 3 values and 1 for grayscale). To tell the model this, this information has to be added to the information that is transferred so that it can be extracted on the other side. The first bytes that gets encoded will relay how many of the following bytes are allocated things like height, width and colorspace and other information that must be transferred. As each byte can only transcribe 0-255, encoding a number such as 108019203 (HD), would be very hard. Thus, if the first three bytes are 3, 4 and 1, the next 3 bytes are allocated to height, the next 4 are allocated to width and the last one to colorspace. This can then be added together on the other side to make a larger number than 255. Lastly, Torcs must write a zero to the aforementioned file to say that the model is no longer ready to receive anything.

In the model, after having communicated that it is ready to receive, the fifo file is opened and the message is received as a binary string. Using NumPyâ€™s frombuffer function, this can be converted from a string of bits to a NumPy array and typecast as an integer. The next step is to extract the height, width and colorspace information that was encoded into the string. After this has been extracted, the model must then take these values and remove them from the NumPy array as these values are not a part of the image. The image is then reshaped from a 1d vector of integers to a 3d matrix of integers. Lastly, due to the image being taken directly from the image buffer, the image is upside down and mirrored. This must be reverted and then you will have the image as it will be displaye
